{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d8b5f1-2e78-4ec9-bbc5-eaf1fd36a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction - FIPS\n",
    "# Version 5\n",
    "## 1/5/25\n",
    "## 19:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53d1c42-37c2-4f01-a34a-c88d27291900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#State County City FIPS \n",
    "\n",
    "# Third Party Source\n",
    "    # SimpleMaps.com \n",
    "        # CSV download\n",
    "\n",
    "    # Terms state I have to reference their website, \n",
    "        # Reference Link\n",
    "        # https://simplemaps.com/data/us-cities\n",
    "\n",
    "\n",
    "# FCC Gov\n",
    "    # FIPS for state and County only. Text file hosted. \n",
    "        # https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt\n",
    "\n",
    "\n",
    "# Transportation.gov\n",
    "# https://data.transportation.gov/Railroads/State-County-and-City-FIPS-Reference-Table/eek5-pv8d/about_data\n",
    "\n",
    "    # API Endpoint\n",
    "        # JSON or CSV\n",
    "\n",
    "        # API Link:\n",
    "        # https://data.transportation.gov/resource/eek5-pv8d.json\n",
    "    \n",
    "        # API Documentation\n",
    "        # https://dev.socrata.com/foundry/data.transportation.gov/eek5-pv8d\n",
    "    \n",
    "        # How to query more than 1000 rows of a dataset\n",
    "        #https://support.socrata.com/hc/en-us/articles/202949268-How-to-query-more-than-1000-rows-of-a-dataset\n",
    "    \n",
    "    \n",
    "        # Needs App Token\n",
    "            # Created Login.Gov Account\n",
    "    \n",
    "            # App Token\n",
    "            # G9y46iRQiv4jix5v8fCATdd2B\n",
    "    \n",
    "        # Will require that I use Offset due to default limit of 1000\n",
    "        # I could probabaly modify my UFO Data code to work with this. \n",
    "        # Dataset has a total of 39,792 rows. \n",
    "\n",
    "    # Also have local csv file download of the dataset\n",
    "\n",
    "\n",
    "    # Dataset contains 9 columns\n",
    "        # State Name \n",
    "        # County Name\n",
    "        # City Name\n",
    "        # State Code\n",
    "        # State FIPS Code\n",
    "        # County Code\n",
    "        # StCnty FIPS Code \n",
    "        # City Code\n",
    "        # StCntyCity FIPS Code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Dev docs On Query Commands\n",
    "        # Link: https://dev.socrata.com/docs/queries/\n",
    "\n",
    "        # If I'm doing URL encoding, I would just need to add a to the end of the url. For python, I will need to add the filter condition as an argument to the client get function [client.get9()]\n",
    "        \n",
    "            # Get Row Count using Sodapy/Socrata\n",
    "                # Add \"?$select=count(*)\" to the end of the get request (? is added if it's the first filter, & is added after each filter to add an additional. )\n",
    "                    # https://data.transportation.gov/resource/eek5-pv8d.json?$select=\"count(*)\"\n",
    "\n",
    "\n",
    "            #So I believe what I will need to do to hadnle the query limit is increment an offset with the limit arguement. \n",
    "                # 'offset' assigned to the end of the previous query limit. \n",
    "                    # first run: client.get(\"client\", limit=\"2000\", offset=\"0\")\n",
    "                    # second run: client.get(\"client\", limit=\"2000\", offset=\"2000\")\n",
    "\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a567250d-b152-4d97-9e3d-07c26a04085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Socrata Sodapy\n",
    "from sodapy import Socrata\n",
    "\n",
    "# NB Importer\n",
    "import nbimporter\n",
    "\n",
    "## Folder Manager\n",
    "import folder_manager as fm\n",
    "\n",
    "## Archive Module \n",
    "import archive_module as archive_tool\n",
    "\n",
    "## Checkpoint Tool\n",
    "import data_cleaning_checkpoint_module as CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21399fa1-e344-4c41-b858-abcede330ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global raw_fips_data_downloads_folder_path\n",
    "\n",
    "main_results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67935740-74e5-42e2-9aec-49cf87878499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_working_directories():\n",
    "\n",
    "    global raw_fips_data_downloads_folder_path\n",
    "\n",
    "    raw_fips_data_downloads_folder_path = fm.get_folder_path(\"raw_FIPS_Data\")\n",
    "    \n",
    "    cleaned_fips_data_folder_path = fm.get_folder_path(\"cleaned_FIPS_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175f1b50-5bbf-45b9-8d14-a6de6dc485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Initializes Folder Manager Requirements\n",
    "    fm.initialize_folder_paths()\n",
    "\n",
    "    # Initializes The Folders for This Notebook\n",
    "    setup_working_directories()\n",
    "    \n",
    "    client = Socrata(\"data.transportation.gov\", \"G9y46iRQiv4jix5v8fCATdd2B\")\n",
    "    \n",
    "    # Example authenticated client (needed for non-public datasets):\n",
    "    # client = Socrata(data.transportation.gov,\n",
    "    #                  MyAppToken,\n",
    "    #                  username=\"user@example.com\",\n",
    "    #                  password=\"AFakePassword\")\n",
    "    \n",
    "    #client = Socrata(\"data.transportation.gov\",\n",
    "                    #\"G9y46iRQiv4jix5v8fCATdd2B\",\n",
    "                    #username=\"dantydcook@gmail.com\",\n",
    "                    #password=\"_wv:bpe$J4MZy_'\")\n",
    "    \n",
    "    # First 2000 results, returned as JSON from API / converted to Python list of\n",
    "    # dictionaries by sodapy.\n",
    "    \n",
    "    record_count_result = client.get(\"eek5-pv8d\", select=\"count(*)\")\n",
    "    \n",
    "    run_results = client.get(\"eek5-pv8d\", limit=2000)\n",
    "    \n",
    "    # Returns a list of dictionary items\n",
    "    #print(record_count_result)\n",
    "    \n",
    "    # Returns the value. Must Index into List then get value of the key. \n",
    "    #print(f'Total Records: {record_count_result[0][\"count\"]}')\n",
    "    \n",
    "    # Assigning Total_row_count with an integer return of the count dictionary value from the get request. \n",
    "    total_row_count = int(record_count_result[0][\"count\"])\n",
    "    \n",
    "    # Assigning Limit\n",
    "    limit = 2000\n",
    "    \n",
    "    # Total Loops is total_row_count int divided by limit\n",
    "    total_loops = (total_row_count // limit) \n",
    "    \n",
    "    # If check for modulo of total_loops / limit\n",
    "    if total_loops % limit != 0:\n",
    "        total_loops += 1\n",
    "    \n",
    "    # print total loops\n",
    "    #print(f\"Total Loops: {total_loops}\\n\")\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    run_results_df = pd.DataFrame.from_records(run_results)\n",
    "    \n",
    "    # Print DF\n",
    "    #run_results_df\n",
    "    \n",
    "    # Loop counter Default Assignment\n",
    "    loop_counter = 0\n",
    "    \n",
    "    # Offset Index\n",
    "    offset_index = 0\n",
    "    \n",
    "    # results main dataframe\n",
    "    \n",
    "    export_start_index = 0\n",
    "    \n",
    "    #column_names = client.get(\"eek5-pv8d\", limit=\"1\")\n",
    "    metadata = client.get_metadata(\"eek5-pv8d\")\n",
    "    \n",
    "    #print(column_names)\n",
    "    #print(metadata)\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    column_datatypes= []\n",
    "    \n",
    "    dataset_schema = {}\n",
    "    \n",
    "    for column in metadata['columns']:\n",
    "    \n",
    "        #print(column['fieldName'])\n",
    "        column_names.append(column['fieldName'])\n",
    "    \n",
    "        if column['dataTypeName'] == \"text\":\n",
    "            column_datatypes.append(\"str\")\n",
    "    \n",
    "    dataset_schema = dict(zip(column_names, column_datatypes))\n",
    "    \n",
    "    #print(dataset_schema)\n",
    "    \n",
    "    main_results_df = pd.DataFrame(columns=dataset_schema).astype(dataset_schema)\n",
    "    \n",
    "    export_end_index = 0\n",
    "    \n",
    "    while loop_counter <= total_loops:\n",
    "    \n",
    "        #print(f\"loop started: {loop_counter}\")\n",
    "    \n",
    "        #print(\"client get\")\n",
    "        loop_run_results = client.get(\"eek5-pv8d\", limit=\"2000\", offset=offset_index)\n",
    "        #print(f\"offset {offset_index}\")\n",
    "    \n",
    "        #print(\"if-else\")\n",
    "        if main_results_df.empty:\n",
    "            #print(\"if entered\")\n",
    "            main_results_df = pd.DataFrame.from_records(loop_run_results)\n",
    "        else:\n",
    "            #print(\"else entered\")\n",
    "            loop_iteration_results = pd.DataFrame.from_records(loop_run_results)\n",
    "            main_results_df = pd.concat([main_results_df, loop_iteration_results])\n",
    "    \n",
    "        #print(f\"export end index prior update {export_end_index}\")\n",
    "        export_end_index = export_start_index + (limit * (loop_counter + 1))\n",
    "        #print(f\"export end index post update {export_end_index}\")\n",
    "        \n",
    "        offset_index = export_end_index\n",
    "        #print(f\"Offset_index: {offset_index}\")\n",
    "        \n",
    "        loop_counter += 1\n",
    "        #print(f\"loop ends, coutner increased {loop_counter}\")\n",
    "    \n",
    "    main_results_df\n",
    "    \n",
    "    #file_name = \"raw_fips_master_data\"\n",
    "    \n",
    "    #main_results_df.to_csv(raw_FIPS_Data_Downloads_Folder_Path + \"/\" + file_name + \".csv\", index=False)\n",
    "\n",
    "    CheckPoint.create_checkpoint(\"raw_FIPS_Data\", \"raw_fips_master_data\", main_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489be918-1cf2-43f8-ab18-9a0ddb102c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
