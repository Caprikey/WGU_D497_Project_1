{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bf1c52-ed8d-4a12-b850-ff6ccbcd199d",
   "metadata": {},
   "source": [
    "### FIPS Data Extraction\n",
    "\n",
    "Extraction of the FIPS data from the United States Department Of Transportation API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d8b5f1-2e78-4ec9-bbc5-eaf1fd36a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraction - FIPS\n",
    "# Version 8\n",
    "## 1/26/25\n",
    "## 19:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902bd975-3e56-4946-9f6c-39a0ed4c234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import System Module \n",
    "import sys\n",
    "\n",
    "# Import OS Module\n",
    "import os\n",
    "\n",
    "# Add the root directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Now you can use absolute imports\n",
    "from d497_helpers import checkpoint_helper as CheckPoint, config\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Socrata Sodapy\n",
    "from sodapy import Socrata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175f1b50-5bbf-45b9-8d14-a6de6dc485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "# According the API's documentation there is a limited of 200o items that can be capture during each request. \n",
    "# Main function allows performs the loop request of the API iteration every 2000 items and saves all to a single dataframe. \n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    client = Socrata(\"data.transportation.gov\", config.global_dot_api_key)\n",
    "    \n",
    "    # Example authenticated client (needed for non-public datasets):\n",
    "    # client = Socrata(data.transportation.gov,\n",
    "    #                  MyAppToken,\n",
    "    #                  username=\"user@example.com\",\n",
    "    #                  password=\"AFakePassword\")\n",
    "    \n",
    "    #client = Socrata(\"data.transportation.gov\",\n",
    "                    #\"G9y46iRQiv4jix5v8fCATdd2B\",\n",
    "                    #username=\"dantydcook@gmail.com\",\n",
    "                    #password=\"_wv:bpe$J4MZy_'\")\n",
    "    \n",
    "    # First 2000 results, returned as JSON from API / converted to Python list of\n",
    "    # dictionaries by sodapy.\n",
    "    \n",
    "    record_count_result = client.get(\"eek5-pv8d\", select=\"count(*)\")\n",
    "    \n",
    "    run_results = client.get(\"eek5-pv8d\", limit=2000)\n",
    "    \n",
    "    # Returns a list of dictionary items\n",
    "    #print(record_count_result)\n",
    "    \n",
    "    # Returns the value. Must Index into List then get value of the key. \n",
    "    #print(f'Total Records: {record_count_result[0][\"count\"]}')\n",
    "    \n",
    "    # Assigning Total_row_count with an integer return of the count dictionary value from the get request. \n",
    "    total_row_count = int(record_count_result[0][\"count\"])\n",
    "    \n",
    "    # Assigning Limit\n",
    "    limit = 2000\n",
    "    \n",
    "    # Total Loops is total_row_count int divided by limit\n",
    "    total_loops = (total_row_count // limit) \n",
    "    \n",
    "    # If check for modulo of total_loops / limit\n",
    "    if total_loops % limit != 0:\n",
    "        total_loops += 1\n",
    "    \n",
    "    # print total loops\n",
    "    #print(f\"Total Loops: {total_loops}\\n\")\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    run_results_df = pd.DataFrame.from_records(run_results)\n",
    "    \n",
    "    # Print DF\n",
    "    #run_results_df\n",
    "    \n",
    "    # Loop counter Default Assignment\n",
    "    loop_counter = 0\n",
    "    \n",
    "    # Offset Index\n",
    "    offset_index = 0\n",
    "    \n",
    "    # results main dataframe\n",
    "    export_start_index = 0\n",
    "    \n",
    "    #column_names = client.get(\"eek5-pv8d\", limit=\"1\")\n",
    "    metadata = client.get_metadata(\"eek5-pv8d\")\n",
    "    \n",
    "    #print(column_names)\n",
    "    #print(metadata)\n",
    "\n",
    "    # Creating blank list called \"column_names\" to store the names for each column\n",
    "    column_names = []\n",
    "\n",
    "    # Creating a blank list called \"column_datatypes\" to store the datatype values for each column\n",
    "    column_datatypes= []\n",
    "\n",
    "    # Creating a blank dictionary called \"dataset_scheme\" to store the the column name with the associated column datatype as a dictionary file. \n",
    "    dataset_schema = {}\n",
    "\n",
    "    # for loop to get the capture the column name and it's associated data type and append them to their respective lists. \n",
    "    for column in metadata['columns']:\n",
    "    \n",
    "        #print(column['fieldName'])\n",
    "        column_names.append(column['fieldName'])\n",
    "    \n",
    "        if column['dataTypeName'] == \"text\":\n",
    "            column_datatypes.append(\"str\")\n",
    "\n",
    "    # Assigning the dataset_schema dictionary with a column names and column datatypes lists by using the zip and dict functions. \n",
    "    dataset_schema = dict(zip(column_names, column_datatypes))\n",
    "    \n",
    "    #print(dataset_schema)\n",
    "\n",
    "    # Creating a dataframe \n",
    "    main_results_df = pd.DataFrame(columns=dataset_schema).astype(dataset_schema)\n",
    "\n",
    "    # export end index counter\n",
    "    export_end_index = 0\n",
    "\n",
    "    # while loop\n",
    "    while loop_counter <= total_loops:\n",
    "    \n",
    "        #print(f\"loop started: {loop_counter}\")\n",
    "    \n",
    "        #print(\"client get\")\n",
    "        loop_run_results = client.get(\"eek5-pv8d\", limit=\"2000\", offset=offset_index)\n",
    "        #print(f\"offset {offset_index}\")\n",
    "    \n",
    "        #print(\"if-else\")\n",
    "        if main_results_df.empty:\n",
    "            #print(\"if entered\")\n",
    "            main_results_df = pd.DataFrame.from_records(loop_run_results)\n",
    "        else:\n",
    "            #print(\"else entered\")\n",
    "            loop_iteration_results = pd.DataFrame.from_records(loop_run_results)\n",
    "            main_results_df = pd.concat([main_results_df, loop_iteration_results])\n",
    "    \n",
    "        #print(f\"export end index prior update {export_end_index}\")\n",
    "        export_end_index = export_start_index + (limit * (loop_counter + 1))\n",
    "        #print(f\"export end index post update {export_end_index}\")\n",
    "        \n",
    "        offset_index = export_end_index\n",
    "        #print(f\"Offset_index: {offset_index}\")\n",
    "        \n",
    "        loop_counter += 1\n",
    "        #print(f\"loop ends, coutner increased {loop_counter}\")\n",
    "    \n",
    "    main_results_df\n",
    "    \n",
    "    #file_name = \"raw_fips_master_data\"\n",
    "    \n",
    "    #main_results_df.to_csv(raw_FIPS_Data_Downloads_Folder_Path + \"/\" + file_name + \".csv\", index=False)\n",
    "\n",
    "    CheckPoint.create_checkpoint(\"raw_fips_data\", \"raw_fips_master_data\", main_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c30267-1783-48ef-9390-a0c351ab7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ed838-4b16-4a9f-925e-bba129751151",
   "metadata": {},
   "source": [
    "## [Next Step: UFO Data Extraction](data_extraction_ufo.ipynb)\n",
    "---\n",
    "#### [Return To Landing Page](order_of_operations_landing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
